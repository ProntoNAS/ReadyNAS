<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<HTML>
<HEAD>
 <META NAME="GENERATOR" CONTENT="SGML-Tools 1.0.9">
 <TITLE>The Software-RAID HOWTO: Performance</TITLE>
 <LINK HREF="Software-RAID.HOWTO-8.html" REL=next>
 <LINK HREF="Software-RAID.HOWTO-6.html" REL=previous>
 <LINK HREF="Software-RAID.HOWTO.html#toc7" REL=contents>
</HEAD>
<BODY>
<A HREF="Software-RAID.HOWTO-8.html">Next</A>
<A HREF="Software-RAID.HOWTO-6.html">Previous</A>
<A HREF="Software-RAID.HOWTO.html#toc7">Contents</A>
<HR>
<H2><A NAME="s7">7. Performance</A></H2>

<P>This section contains a number of benchmarks from a real-world system
using software RAID.
<P>Benchmarks are done with the <CODE>bonnie</CODE> program, and at all times
on files twice- or more the size of the physical RAM in the machine.
<P>The benchmarks here <EM>only</EM> measures input and output bandwidth
on one large single file.  This is a nice thing to know, if it's
maximum I/O throughput for large reads/writes one is interested in.
However, such numbers tell us little about what the performance would
be if the array was used for a news spool, a web-server, etc. etc.
Always keep in mind, that benchmarks numbers are the result of running
a ``synthetic'' program. Few real-world programs do what
<CODE>bonnie</CODE> does, and although these I/O numbers are nice to look
at, they are not ultimate real-world-appliance performance
indicators. Not even close.
<P>For now, I only have results from my own machine. The setup is:
<UL>
<LI>Dual Pentium Pro 150 MHz</LI>
<LI>256 MB RAM (60 MHz EDO)</LI>
<LI>Three IBM UltraStar 9ES 4.5 GB, SCSI U2W</LI>
<LI>Adaptec 2940U2W</LI>
<LI>One IBM UltraStar 9ES 4.5 GB, SCSI UW</LI>
<LI>Adaptec 2940 UW</LI>
<LI>Kernel 2.2.7 with RAID patches</LI>
</UL>
<P>The three U2W disks hang off the U2W controller, and the UW disk off
the UW controller.
<P>It seems to be impossible to push much more than 30 MB/s thru the SCSI
busses on this system, using RAID or not. My guess is, that because
the system is fairly old, the memory bandwidth sucks, and thus limits
what can be sent thru the SCSI controllers.
<P>
<H2><A NAME="ss7.1">7.1 RAID-0</A>
</H2>

<P><B>Read</B> is <B>Sequential block input</B>, and <B>Write</B>
is <B>Sequential block output</B>. File size was 1GB in all
tests. The tests where done in single-user mode. The SCSI driver was
configured not to use tagged command queuing.
<P>
<CENTER><TABLE BORDER><TR><TD>
<BR>
Chunk size </TD><TD> Block size </TD><TD> Read KB/s </TD><TD> Write KB/s </TD></TR><TR><TD>
</TD></TR><TR><TD>
4k </TD><TD> 1k </TD><TD> 19712 </TD><TD> 18035 </TD></TR><TR><TD>
4k </TD><TD> 4k </TD><TD> 34048 </TD><TD> 27061 </TD></TR><TR><TD>
8k </TD><TD> 1k </TD><TD> 19301 </TD><TD> 18091 </TD></TR><TR><TD>
8k </TD><TD> 4k </TD><TD> 33920 </TD><TD> 27118 </TD></TR><TR><TD>
16k </TD><TD> 1k </TD><TD> 19330 </TD><TD> 18179 </TD></TR><TR><TD>
16k </TD><TD> 2k </TD><TD> 28161 </TD><TD> 23682 </TD></TR><TR><TD>
16k </TD><TD> 4k </TD><TD> 33990 </TD><TD> 27229 </TD></TR><TR><TD>
32k </TD><TD> 1k </TD><TD> 19251 </TD><TD> 18194 </TD></TR><TR><TD>
32k </TD><TD> 4k </TD><TD> 34071 </TD><TD> 26976

</TD></TR></TABLE></CENTER>
<P>From this it seems that the RAID chunk-size doesn't make that much
of a difference. However, the ext2fs block-size should be as large as
possible, which is 4KB (eg. the page size) on IA-32.
<P>
<H2><A NAME="ss7.2">7.2 RAID-0 with TCQ</A>
</H2>

<P>This time, the SCSI driver was configured to use tagged command
queuing, with a queue depth of 8. Otherwise, everything's the same as
before.
<P>
<CENTER><TABLE BORDER><TR><TD>
<BR>
Chunk size </TD><TD> Block size </TD><TD> Read KB/s </TD><TD> Write KB/s </TD></TR><TR><TD>
</TD></TR><TR><TD>
32k </TD><TD> 4k </TD><TD> 33617 </TD><TD> 27215

</TD></TR></TABLE></CENTER>
<P>No more tests where done. TCQ seemed to slightly increase write
performance, but there really wasn't much of a difference at all.
<P>
<H2><A NAME="ss7.3">7.3 RAID-5</A>
</H2>

<P>The array was configured to run in RAID-5 mode, and similar tests
where done.
<P>
<CENTER><TABLE BORDER><TR><TD>
<BR>
Chunk size </TD><TD> Block size </TD><TD> Read KB/s </TD><TD> Write KB/s </TD></TR><TR><TD>
</TD></TR><TR><TD>
8k </TD><TD> 1k </TD><TD> 11090 </TD><TD> 6874 </TD></TR><TR><TD>
8k </TD><TD> 4k </TD><TD> 13474 </TD><TD> 12229 </TD></TR><TR><TD>
32k </TD><TD> 1k </TD><TD> 11442 </TD><TD> 8291 </TD></TR><TR><TD>
32k </TD><TD> 2k </TD><TD> 16089 </TD><TD> 10926 </TD></TR><TR><TD>
32k </TD><TD> 4k </TD><TD> 18724 </TD><TD> 12627

</TD></TR></TABLE></CENTER>
<P>Now, both the chunk-size and the block-size seems to actually make a
difference.
<P>
<H2><A NAME="ss7.4">7.4 RAID-10</A>
</H2>

<P>RAID-10 is ``mirrored stripes'', or, a RAID-1 array of two RAID-0
arrays. The chunk-size is the chunk sizes of both the RAID-1 array and
the two RAID-0 arrays. I did not do test where those chunk-sizes
differ, although that should be a perfectly valid setup.
<P>
<CENTER><TABLE BORDER><TR><TD>
<BR>
Chunk size </TD><TD> Block size </TD><TD> Read KB/s </TD><TD> Write KB/s </TD></TR><TR><TD>
</TD></TR><TR><TD>
32k </TD><TD> 1k </TD><TD> 13753 </TD><TD> 11580 </TD></TR><TR><TD>
32k </TD><TD> 4k </TD><TD> 23432 </TD><TD> 22249

</TD></TR></TABLE></CENTER>
<P>No more tests where done. The file size was 900MB, because the four
partitions involved where 500 MB each, which doesn't give room for a
1G file in this setup (RAID-1 on two 1000MB arrays).
<P>
<P>
<HR>
<A HREF="Software-RAID.HOWTO-8.html">Next</A>
<A HREF="Software-RAID.HOWTO-6.html">Previous</A>
<A HREF="Software-RAID.HOWTO.html#toc7">Contents</A>
</BODY>
</HTML>

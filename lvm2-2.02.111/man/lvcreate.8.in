.TH LVCREATE 8 "LVM TOOLS #VERSION#" "Sistina Software UK" \" -*- nroff -*-
.SH NAME
lvcreate \- create a logical volume in an existing volume group
.SH SYNOPSIS
.B lvcreate
.RB [ \-\-addtag
.IR Tag ]
.RB [ \-\-alloc
.IR AllocationPolicy ]
.RB [ \-a | \-\-activate
.RI [ a | e | l ]{ y | n }]
.RB [ \-k | \-\-setactivationskip
.RI { y | n }]
.RB [ \-K | \-\-ignoreactivationskip ]
.RB [ \-A | \-\-autobackup
.RI { y | n }]
.RB [ \-\-commandprofile
.IR ProfileName ]
.RB [ \-C | \-\-contiguous
.RI { y | n }]
.RB [ \-d | \-\-debug ]
.RB [ \-h | \-? | \-\-help ]
.RB [ \-\-noudevsync ]
.RB [ \-\-ignoremonitoring ]
.RB [ \-\-metadataprofile
.IR ProfileName ]
.RB [ \-\-monitor
.RI { y | n }]
.RB [ \-\-[raid]maxrecoveryrate
.IR Rate ]
.RB [ \-\-[raid]minrecoveryrate
.IR Rate ]
.RB [ \-i | \-\-stripes
.IR Stripes
.RB [ \-I | \-\-stripesize
.IR StripeSize ]]
.RB {[ \-l | \-\-extents
.IR LogicalExtentsNumber [ % { VG | PVS | FREE }]
|
.BR \-L | \-\-size
.IR LogicalVolumeSize [ bBsSkKmMgGtTpPeE ]]
|
.BR \-V | \-\-virtualsize
.IR VirtualSize [ bBsSkKmMgGtTpPeE ]}
.RB [ \-M | \-\-persistent
.RI { y | n }]
.RB [ \-\-minor
.IR minor ]
.RB [ \-m | \-\-mirrors
.IR Mirrors
.RB [ \-\-nosync ]
.RB [ \-\-mirrorlog
.RI { disk | core | mirrored }
|
.BR \-\-corelog ]
.RB [ \-R | \-\-regionsize
.IR MirrorLogRegionSize ]]
.RB [ \-n | \-\-name
.IR LogicalVolume { Name | Path }]
.RB [ \-p | \-\-permission
.RI { r | rw }]
.RB [ \-r | \-\-readahead
.RI { ReadAheadSectors | auto | none }]
.RB [ \-t | \-\-test ]
.RB [ \-T | \-\-thin
.RB [ \-\-cachemode
.RI { writeback | writethrough }
.RB [ \-c | \-\-chunksize
.IR ChunkSize [ bBsSkKmMgG ]]
.RB [ \-\-discards
.RI { ignore | nopassdown | passdown }]
.RB [ \-\-poolmetadatasize
.IR MetadataVolumeSize [ bBsSkKmMgG ]]
.RB [ \-\-poolmetadataspare
.RI { y | n }]]
.RB [ \-\-thinpool
.IR ThinPoolLogicalVolume { Name | Path }
.RB [ \-s | \-\-snapshot
.RI [ VolumeGroup { Name | Path }/]
.IR ExternalOriginLogicalVolumeName ]]
.RB [ \-\-type
.IR SegmentType ]
.RB [ \-v | \-\-verbose ]
.RB [ \-W | \-\-wipesignatures ]
.RB [ \-Z | \-\-zero
.RI { y | n }]
.IR VolumeGroup { Name | Path }[/ ThinPoolLogicalVolumeName ]
.RI [ PhysicalVolumePath [ :PE [ \-PE ]]...]
.br

.B lvcreate
.RB [ \-l | \-\-extents
.IR LogicalExtentsNumber [ % { ORIGIN | VG | PVS | FREE }]
|
.BR \-L | \-\-size
.IR LogicalVolumeSize [ bBsSkKmMgGtTpPeE ]]
.RB [ \-c | \-\-chunksize
.IR ChunkSize [ bBsSkK ]]
.RB [ \-\-commandprofile
.IR Profilename ]
.RB [ \-\-noudevsync ]
.RB [ \-\-ignoremonitoring ]
.RB [ \-\-metadataProfile
.IR ProfileName ]
.RB [ \-\-monitor
.RI { y | n }]
.RB [ \-n | \-\-name
.IR SnapshotLogicalVolume { Name | Path }]
.BR \-s | \-\-snapshot
.RI {[ VolumeGroup { Name | Path }/] OriginalLogicalVolumeName
.BR \-V | \-\-virtualsize
.IR VirtualSize [ bBsSkKmMgGtTpPeE ]}
.br

.SH DESCRIPTION
lvcreate creates a new logical volume in a volume group (see
.BR vgcreate "(8), " vgchange (8))
by allocating logical extents from the free physical extent pool
of that volume group.  If there are not enough free physical extents then
the volume group can be extended (see
.BR vgextend (8))
with other physical volumes or by reducing existing logical volumes
of this volume group in size (see
.BR lvreduce (8)).
If you specify one or more PhysicalVolumes, allocation of physical
extents will be restricted to these volumes.
.br
.br
The second form supports the creation of snapshot logical volumes which
keep the contents of the original logical volume for backup purposes.
.SH OPTIONS
See
.BR lvm (8)
for common options.
.TP
.IR \fB\-a ", " \fB\-\-activate " {" y | ay | n | ey | en | ly | ln }
Controls the availability of the Logical Volumes for immediate use after
the command finishes running.
By default, new Logical Volumes are activated (\fB\-a\fIy\fR).
If it is possible technically, \fB\-a\fIn\fR will leave the new Logical
Volume inactive. But for example, snapshots can only be created
in the active state so \fB\-a\fIn\fR cannot be used with \fB\-\-snapshot\fP.
Normally the \fB\-\-zero\fP \fIn\fP argument has to be supplied too because
zeroing (the default behaviour) also requires activation.
If autoactivation option is used (\fB\-a\fIay\fR), the logical volume is
activated only if it matches an item in the
.B activation/auto_activation_volume_list
set in \fBlvm.conf\fP(5).
For autoactivated logical volumes, \fB\-\-zero\fP \fIn\fP and
\fB\-\-wipesignatures\fP \fIn\fP is always assumed and it can't
be overridden. If the clustered locking is enabled,
\fB\-a\fIey\fR will activate exclusively on one node and
.IR \fB\-a { a | l } y
will activate only on the local node.
.TP
.IR \fB\-k ", " \fB\-\-setactivationskip "  {" y | n }
Controls whether Logical Volumes are persistently flagged to be skipped during
activation. By default, thin snapshot volumes are flagged for activation skip.
To activate such volumes, an extra \fB\-K/\-\-ignoreactivationskip\fP option must
be used. The flag is not applied during deactivation.
Use \fBlvchange \-k/\-\-setactivationskip {y|n}\fP command to attach or
detach the flag for existing volumes. To see whether the flag is attached,
use \fBlvs\fP command where the state of the flag is reported within
\fBlv_attr\fP bits.
.TP
.BR \-K ", " \-\-ignoreactivationskip
Ignore the flag to skip Logical Volumes during activation.

.TP
.IR \fB\-\-cachemode " {" writeback | writethrough }
Specifying a cache mode determines when the writes to a cache LV
are considered complete.  When \fIwriteback\fP is specified, a write is
considered complete as soon as it is stored in the cache pool LV.
If \fIwritethough\fP is specified, a write is considered complete only
when it has been stored in the cache pool LV and on the origin LV.
While \fIwritethrough\fP may be slower for writes, it is more
resilient if something should happen to a device associated with the
cache pool LV.

.TP
.BR \-c ", " \-\-chunksize " " \fIChunkSize [ \fIbBsSkKmMgG ]
Gives the size of chunk for snapshot, cache pool and thin pool logical volumes.
Default unit is in kilobytes.
.br
For snapshots the value must be power of 2 between 4KiB and 512KiB
and the default value is 4.
.br
For cache pool LVs the value must be between 32KiB and 1GiB.  The default
is 64KiB.  Values must be a multiple of 32KiB.
.br
For thin pools the value must be between 64KiB and
1GiB and the default value starts with 64 and scales
up to fit the pool metadata size within 128MiB,
if the pool metadata size is not specified.
Thin pool target version <1.4 requires the value to be a power of 2.
The newer target version relaxes limitation to be a multiple of 64KiB.
For target version <1.5 discard is not supported for non power of 2 values.
.TP
.BR \-C ", " \-\-contiguous " {" \fIy | \fIn }
Sets or resets the contiguous allocation policy for
logical volumes. Default is no contiguous allocation based
on a next free principle.
.TP
.BR \-\-discards " {" \fIignore | \fInopassdown | \fIpassdown }
Sets discards behavior for thin pool.
Default is \fIpassdown\fP.
.TP
.BR \-i ", " \-\-stripes " " \fIStripes
Gives the number of stripes.
This is equal to the number of physical volumes to scatter
the logical volume.  When creating a RAID 4/5/6 logical volume,
the extra devices which are necessary for parity are
internally accounted for.  Specifying
.BI \-i 3
would use 3 devices for striped logical volumes,
4 devices for RAID 4/5, and 5 devices for RAID 6.  Alternatively,
RAID 4/5/6 will stripe across all PVs in the volume group or
all of the PVs specified if the
.B \-i
argument is omitted.
.TP
.BR \-I ", " \-\-stripesize " " \fIStripeSize
Gives the number of kilobytes for the granularity of the stripes.
.br
StripeSize must be 2^n (n = 2 to 9) for metadata in LVM1 format.
For metadata in LVM2 format, the stripe size may be a larger
power of 2 but must not exceed the physical extent size.
.TP
.B \-\-ignoremonitoring
Make no attempt to interact with dmeventd unless \fB\-\-monitor\fP
is specified.
.TP
.IR \fB\-l ", " \fB\-\-extents " " LogicalExtentsNumber [ % { VG | PVS | FREE | ORIGIN }]
Gives the number of logical extents to allocate for the new
logical volume.  The total number of physical extents allocated will be
greater than this, for example, if the volume is mirrored.
The number can also be expressed as a percentage of the total space
in the Volume Group with the suffix \fI%VG\fR, as a percentage of the
remaining free space in the Volume Group with the suffix \fI%FREE\fR, as a
percentage of the remaining free space for the specified
PhysicalVolume(s) with the suffix \fI%PVS\fR, or (for a snapshot) as a
percentage of the total space in the Origin Logical Volume with the
suffix \fI%ORIGIN\fR (i.e. \fI100%ORIGIN\fR provides space for the whole origin).
When expressed as a percentage, the number is treated
as an approximate upper limit for the total number of physical extents
to be allocated (including extents used by any mirrors, for example).
.TP
.IR \fB\-L ", " \fB\-\-size " " LogicalVolumeSize [ bBsSkKmMgGtTpPeE ]
Gives the size to allocate for the new logical volume.
A size suffix of \fIB\fR for bytes, \fIS\fR for sectors as 512 bytes,
\fIK\fR for kilobytes, \fIM\fR for megabytes,
\fIG\fR for gigabytes, \fIT\fR for terabytes, \fIP\fR for petabytes
or \fIE\fR for exabytes is optional.
.br
Default unit is megabytes.
.TP
.BR \-m ", " \-\-mirrors " " \fIMirrors
Creates a mirrored logical volume with \fIMirrors\fP copies.
For example, specifying
.BI \-m 1
would result in a mirror with two-sides; that is,
a linear volume plus one copy.

Specifying the optional argument \fB\-\-nosync\fP will cause the creation
of the mirror to skip the initial resynchronization.  Any data written
afterwards will be mirrored, but the original contents will not be
copied.  This is useful for skipping a potentially long and resource
intensive initial sync of an empty device.

There are two implementations of mirroring which can be used and correspond
to the "raid1" and "mirror" segment types.  The default is "raid1".  See the
\fB\-\-type\fP option for more information if you would like to use the
legacy "mirror" segment type.  The \fB\-\-mirrorlog\fP and \fB\-\-corelog\fP
options apply to the "mirror" segment type only.

The optional argument \fB\-\-mirrorlog\fP specifies the type of log to be
used for logical volumes utilizing the legacy "mirror" segment type.
The default is \fIdisk\fP, which is persistent and requires
a small amount of storage space, usually on a separate device from the
data being mirrored.  Using \fIcore\fP means the mirror is regenerated
by copying the data from the first device each time the logical
volume is activated, like after every reboot.  Using \fImirrored\fP
will create a persistent log that is itself mirrored.

When the legacy "mirror" segment type is used, the optional argument
\fB\-\-corelog\fP is equivalent to \fB\-\-mirrorlog\fP \fIcore\fP.
.TP
.BR \-\-metadataprofile " " \fIProfileName
Uses and attaches the ProfileName configuration profile to the logical
volume metadata. Whenever the logical volume is processed next time,
the profile is automatically applied. If the volume group has another
profile attached, the logical volume profile is preferred.
See \fBlvm.conf\fP(5) for more information about \fBmetadata profiles\fP.
.TP
.IR \fB\-M ", " \fB\-\-persistent " {" y | n }
Set to \fIy\fP to make the minor number specified persistent.
.TP
.B \-\-minor \fIminor
Sets the minor number.
.TP
.BR \-\-monitor " {" \fIy | \fIn }
Starts or avoids monitoring a mirrored, snapshot or thin pool logical volume with
dmeventd, if it is installed.
If a device used by a monitored mirror reports an I/O error,
the failure is handled according to
.B activation/mirror_image_fault_policy
and
.B activation/mirror_log_fault_policy
set in \fBlvm.conf\fP(5).
.TP
.IR \fB\-n ", " \fB\-\-name " " LogicalVolume { Name | Path }
Sets the name for the new logical volume.
.br
Without this option a default name of "lvol#" will be generated where
# is the LVM internal number of the logical volume.
.TP
.IR \fB\-\-[raid]maxrecoveryrate " " \fIRate [ bBsSkKmMgG ]
Sets the maximum recovery rate for a RAID logical volume.  \fIRate\fP
is specified as an amount per second for each device in the array.
If no suffix is given, then KiB/sec/device is assumed.  Setting the
recovery rate to 0 means it will be unbounded.
.TP
.IR \fB\-\-[raid]minrecoveryrate " " \fIRate [ bBsSkKmMgG ]
Sets the minimum recovery rate for a RAID logical volume.  \fIRate\fP
is specified as an amount per second for each device in the array.
If no suffix is given, then KiB/sec/device is assumed.  Setting the
recovery rate to 0 means it will be unbounded.
.TP
.B \-\-noudevsync
Disables udev synchronisation. The
process will not wait for notification from udev.
It will continue irrespective of any possible udev processing
in the background.  You should only use this if udev is not running
or has rules that ignore the devices LVM2 creates.
.TP
.BR \-p ", " \-\-permission " {" \fIr | \fIrw }
Sets access permissions to read only (\fIr\fP) or read and write (\fIrw\fP).
.br
Default is read and write.
.TP
.IR \fB\-\-poolmetadatasize " " MetadataVolumeSize [ bBsSkKmMgG ]
Sets the size of thin pool's metadata logical volume.
Supported values are in range between 2MiB and 16GiB.
Default value is  (Pool_LV_size / Pool_LV_chunk_size * 64b).
Default unit is megabytes.
.TP
.IR \fB\-\-poolmetadataspare " {"  y | n }
Controls creation and maintanence of pool metadata spare logical volume
that will be used for automated pool recovery.
Only one such volume is maintained within a volume group
with the size of the biggest pool metadata volume.
Default is \fIy\fPes.
.TP
.IR \fB\-r ", " \fB\-\-readahead " {" ReadAheadSectors | auto | none }
Sets read ahead sector count of this logical volume.
For volume groups with metadata in lvm1 format, this must
be a value between 2 and 120.
The default value is \fIauto\fP which allows the kernel to choose
a suitable value automatically.
\fINone\fP is equivalent to specifying zero.
.TP
.BR \-R ", " \-\-regionsize " " \fIMirrorLogRegionSize
A mirror is divided into regions of this size (in MiB), and the mirror log
uses this granularity to track which regions are in sync.
.TP
.IR \fB\-s ", " \fB\-\-snapshot " " OriginalLogicalVolume { Name | Path }
Creates a snapshot logical volume (or snapshot) for an existing, so called
original logical volume (or origin).
Snapshots provide a 'frozen image' of the contents of the origin
while the origin can still be updated. They enable consistent
backups and online recovery of removed/overwritten data/files.
Thin snapshot is created when the origin is a thin volume and
the size IS NOT specified. Thin snapshot shares same blocks within
the thin pool volume.
The non thin volume snapshot with the specified size does not need
the same amount of storage the origin has. In a typical scenario,
15-20% might be enough. In case the snapshot runs out of storage, use
.BR lvextend (8)
to grow it. Shrinking a snapshot is supported by
.BR lvreduce (8)
as well. Run
.BR lvs (8)
on the snapshot in order to check how much data is allocated to it.
Note: a small amount of the space you allocate to the snapshot is
used to track the locations of the chunks of data, so you should
allocate slightly more space than you actually need and monitor
(\fB\-\-monitor\fP) the rate at which the snapshot data is growing
so you can \fBavoid\fP running out of space.
If \fB\-\-thinpool\fP is specified, thin volume is created that will
use given original logical volume as an external origin that
serves unprovisioned blocks.
Only read-only volumes can be used as external origins.
To make the volume external origin, lvm expects the volume to be inactive.
External origin volume can be used/shared for many thin volumes
even from different thin pools. See
.BR lvconvert (8)
for online conversion to thin volumes with external origin.
.TP
.IR \fB\-T ", " \fB\-\-thin ", " \fB\-\-thinpool " " ThinPoolLogicalVolume { Name | Path }
Creates thin pool or thin logical volume or both.
Specifying the optional argument \fB\-\-size\fP will cause the creation of
the thin pool logical volume.
Specifying the optional argument \fB\-\-virtualsize\fP will cause
the creation of the thin logical volume from given thin pool volume.
Specifying both arguments will cause the creation of both
thin pool and thin volume using this pool.
See \fBlvmthin\fP(7) for more info about thin provisioning support.
Requires device mapper kernel driver for thin provisioning
from kernel 3.2 or newer.
.TP
.B \-\-type \fISegmentType
Create a logical volume that uses the specified segment type
(e.g.
.IR mirror ( \fB\-m ),
.IR raid5 ,
.IR snapshot ( \fB\-s ),
.IR thin ( \fB\-T ),
.IR thin-pool ,\ ...).
Many segment types have a
commandline switch alias that will enable their use
(\fB\-s\fP is an alias for
.B \-\-type \fIsnapshot\fP).
However, this argument must be used when no existing
commandline switch alias is available for the desired type,
as is the case with
.IR cache ,
.IR error ,
.IR raid1 ,
.IR raid4 ,
.IR raid5 ,
.IR raid6 ,
.IR raid10
or
.IR zero .
See \fBlvmcache\fP(7) for more info about caching support.
Note that the cache segment type requires a dm-cache kernel module version
1.3.0 or greater.

.TP
.BR \-V ", " \-\-virtualsize " " \fIVirtualSize [ \fIbBsSkKmMgGtTpPeE ]
Creates a sparse device of the given size (in MiB by default) using a snapshot
or thinly provisioned device when thin pool is specified.
Anything written to the device will be returned when reading from it.
Reading from other areas of the device will return blocks of zeros.
Virtual snapshot is implemented by creating a hidden virtual device of the
requested size using the zero target.  A suffix of _vorigin is used for
this device. Note: using sparse snapshots is not efficient for larger
device sizes (GiB), thin provisioning should be used for this case.
.TP
.BR \-W ", " \-\-wipesignatures " {" \fIy | \fIn }
Controls wiping of detected signatures on newly created Logical Volume.
If this option is not specified, then by default signature wiping is done
each time the zeroing (\fB\-Z\fP/\fB\-\-zero\fP) is done. This default behaviour
can be controlled by \fBallocation/wipe_signatures_when_zeroing_new_lvs\fP
setting found in \fBlvm.conf\fP(5).
.br
If blkid wiping is used (\fBallocation/use_blkid_wiping setting\fP in \fBlvm.conf\fP(5))
and LVM2 is compiled with blkid wiping support, then \fBblkid\fP(8) library is used
to detect the signatures (use \fBblkid -k\fP command to list the signatures that are recognized).
Otherwise, native LVM2 code is used to detect signatures (MD RAID, swap and LUKS
signatures are detected only in this case).
.br
Logical Volume is not wiped if the read only flag is set.
.TP
.BR \-Z ", " \-\-zero " {" \fIy | \fIn }
Controls zeroing of the first 4KiB of data in the new logical volume.
.br
Default is \fIy\fPes.
.br
Volume will not be zeroed if the read only flag is set.
.br
Snapshot volumes are zeroed always.

.br
Warning: trying to mount an unzeroed logical volume can cause the system to
hang.
.SH Examples
Creates a striped logical volume with 3 stripes, a stripe size of 8KiB
and a size of 100MiB in the volume group named vg00.
The logical volume name will be chosen by lvcreate:
.sp
.B lvcreate \-i 3 \-I 8 \-L 100M vg00

Creates a mirror logical volume with 2 sides with a useable size of 500 MiB.
This operation would require 3 devices (or option
.BI \-\-alloc \ anywhere
) - two for the mirror devices and one for the disk log:
.sp
.B lvcreate \-m1 \-L 500M vg00

Creates a mirror logical volume with 2 sides with a useable size of 500 MiB.
This operation would require 2 devices - the log is "in-memory":
.sp
.B lvcreate \-m1 \-\-mirrorlog core \-L 500M vg00

Creates a snapshot logical volume named "vg00/snap" which has access to the
contents of the original logical volume named "vg00/lvol1"
at snapshot logical volume creation time. If the original logical volume
contains a file system, you can mount the snapshot logical volume on an
arbitrary directory in order to access the contents of the filesystem to run
a backup while the original filesystem continues to get updated:
.sp
.B lvcreate \-\-size 100m \-\-snapshot \-\-name snap /dev/vg00/lvol1

Creates a snapshot logical volume named "vg00/snap" with size
for overwriting 20% of the original logical volume named "vg00/lvol1".:
.sp
.B lvcreate \-s \-l 20%ORIGIN \-\-name snap vg00/lvol1

Creates a sparse device named /dev/vg1/sparse of size 1TiB with space for just
under 100MiB of actual data on it:
.sp
.B lvcreate \-\-virtualsize 1T \-\-size 100M \-\-snapshot \-\-name sparse vg1

Creates a linear logical volume "vg00/lvol1" using physical extents
/dev/sda:0\-7 and /dev/sdb:0\-7 for allocation of extents:
.sp
.B lvcreate \-L 64M \-n lvol1 vg00 /dev/sda:0\-7 /dev/sdb:0\-7

Creates a 5GiB RAID5 logical volume "vg00/my_lv", with 3 stripes (plus
a parity drive for a total of 4 devices) and a stripesize of 64KiB:
.sp
.B lvcreate \-\-type raid5 \-L 5G \-i 3 \-I 64 \-n my_lv vg00

Creates a RAID5 logical volume "vg00/my_lv", using all of the free
space in the VG and spanning all the PVs in the VG:
.sp
.B lvcreate \-\-type raid5 \-l 100%FREE \-n my_lv vg00

Creates a 5GiB RAID10 logical volume "vg00/my_lv", with 2 stripes on
2 2-way mirrors.  Note that the \fB-i\fP and \fB-m\fP arguments behave
differently.
The \fB-i\fP specifies the number of stripes.
The \fB-m\fP specifies the number of
.B additional
copies:
.sp
.B lvcreate \-\-type raid10 \-L 5G \-i 2 \-m 1 \-n my_lv vg00

Creates 100MiB pool logical volume for thin provisioning
build with 2 stripes 64KiB and chunk size 256KiB together with
1TiB thin provisioned logical volume "vg00/thin_lv":
.sp
.B lvcreate \-i 2 \-I 64 \-c 256 \-L100M \-T vg00/pool \-V 1T \-\-name thin_lv

Creates a thin snapshot volume "thinsnap" of thin volume "thinvol" that
will share the same blocks within the thin pool.
Note: the size MUST NOT be specified, otherwise the non-thin snapshot
is created instead:
.sp
.B lvcreate \-s vg00/thinvol \-\-name thinsnap

Creates a thin snapshot volume of read-only inactive volume "origin"
which then becomes the thin external origin for the thin snapshot volume
in vg00 that will use an existing thin pool "vg00/pool":
.sp
.B lvcreate \-s \-\-thinpool vg00/pool  origin

Create a cache pool LV that can later be used to cache one
logical volume.
.sp
.B lvcreate \-\-type cache-pool \-L 1G \-n my_lv_cachepool vg /dev/fast1

If there is an existing cache pool LV, create the large slow
device (i.e. the origin LV) and link it to the supplied cache pool LV,
creating a cache LV.
.sp
.B lvcreate \-\-type cache \-L 100G \-n my_lv vg/my_lv_cachepool /dev/slow1

If there is an existing logical volume, create the small and fast
cache pool LV and link it to the supplied existing logical
volume (i.e. the origin LV), creating a cache LV.
.sp
.B lvcreate \-\-type cache \-L 1G \-n my_lv_cachepool vg/my_lv /dev/fast1

.SH SEE ALSO
.BR lvm (8),
.BR lvm.conf (5),
.BR lvmcache (7),
.BR lvmthin (7),
.BR lvconvert (8),
.BR lvchange (8),
.BR lvextend (8),
.BR lvreduce (8),
.BR lvremove (8),
.BR lvrename (8)
.BR lvs (8),
.BR lvscan (8),
.BR vgcreate (8)

Source: wget
Section: web
Priority: important
Maintainer: Noèl Köthe <noel@debian.org>
Build-Depends: debhelper (>> 5.0.0), gettext, texinfo, libssl-dev (>= 0.9.8), dpatch, info2man
Standards-Version: 3.8.4
Homepage: http://www.gnu.org/software/wget/

Package: wget
Architecture: any
Depends: ${shlibs:Depends}, ${misc:Depends}
Conflicts: wget-ssl
Description: retrieves files from the web
 Wget is a network utility to retrieve files from the Web
 using http(s) and ftp, the two most widely used Internet
 protocols. It works non-interactively, so it will work in
 the background, after having logged off. The program supports
 recursive retrieval of web-authoring pages as well as ftp
 sites -- you can use wget to make mirrors of archives and
 home pages or to travel the Web like a WWW robot.
 .
 Wget works particularly well with slow or unstable connections
 by continuing to retrieve a document until the document is fully
 downloaded. Re-getting files from where it left off works on
 servers (both http and ftp) that support it. Both http and ftp
 retrievals can be time stamped, so wget can see if the remote
 file has changed since the last retrieval and automatically
 retrieve the new version if it has.
 .
 Wget supports proxy servers; this can lighten the network load,
 speed up retrieval, and provide access behind firewalls.
 .
 http://www.gnu.org/software/wget/
